---
title: "SSD"
author: "Shudong Sun"
output: rmarkdown::html_vignette
date: "`r Sys.Date()`"
vignette: >
  %\VignetteIndexEntry{SSD}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE,
  message = FALSE
)
```

# Introduction

SSD is a simulator that generate different sample size data from pilot data based on multivariate guassian distribution. Then it will calculate the corresponding classification error/ARI/AMI and draw the plot which has the same trend as the true data. People can determine the sample size according the plot we draw.



# Preparations
Before we dive into the main task, we need to load the package and an example dataset for our task. The dataset we use is the **pmbc_68k** dataset from [10x Genomics](https://www.10xgenomics.com/resources/datasets/fresh-68-k-pbm-cs-donor-a-1-standard-1-1-0).
```{r setup and load data}
library(SSD)

# load data -----------------------------------------------------------------------------
data_pmbc <- read.csv(system.file("extdata", "data_pmbc_24pc.csv", package = "SSD"),row.names=1)
data = data_pmbc
```
We pre-processed the dataset: we normalize and scale the date at first and then run principal component analysis (PCA) and keep 24 PCs according to *JackStrawPlot* and *ElbowPlot* mentioned in [Seurat - Guided Clustering Tutorial](https://satijalab.org/seurat/articles/pbmc3k_tutorial.html). The *JackStrawPlot* and *ElbowPlot* are shown below:
```{r echo=FALSE, fig.cap="JackStrawPlot", out.width = '100%'}
knitr::include_graphics("https://raw.githubusercontent.com/ShudongSun/SampleSizeDetermination/main/vignettes/pmbc_jackstrawplot.jpeg")
```
```{r echo=FALSE, fig.cap="ElbowPlot", out.width = '100%'}
knitr::include_graphics("https://raw.githubusercontent.com/ShudongSun/SampleSizeDetermination/main/vignettes/pmbc_elbowplot.jpeg")
```

# Task
## With pilot data, draw the plot and determine sample size using the built-in model

The pilot data is extract from the dataset imported before:
```{r}
### use pilot data:
p = 15
num_class = length(table(data$phenoid))
num_PC = length(colnames(data))-1
for(i in 1:num_class){
  class_i_ids = which(data$phenoid == names(table(data$phenoid))[i])
  pilot_i_ids = sample(class_i_ids, p)
  pilot_i_data = data[pilot_i_ids,]
  if(i == 1){
    pilot_data = pilot_i_data
  }else{
    pilot_data = rbind(pilot_data, pilot_i_data)
  }
}
x_pilot = pilot_data[,-length(pilot_data)]
y_pilot = pilot_data[,length(pilot_data)]

print(table(pilot_data$phenoid))
```
In this dataset, *phenoid* is the y label which has 10 classes. In the pilot data, each class has 15 observations.
In the default setting, we use the built-in *random forest* to train the model. The `index` we use is Adjusted Rand Index (ARI).
```{r eval=FALSE}
result_pilot = ssd(x_pilot, y_pilot)
```
```{r echo=FALSE, out.width = '100%'}
knitr::include_graphics("https://raw.githubusercontent.com/ShudongSun/SampleSizeDetermination/main/vignettes/1-1.jpeg")
```
The plot is drawn only based on the pilot data and we could use the plot to determine the sample size if we don't have large enough true. We should focus on the trends of the plots because the results produced by synthetic data are usually better than true data, but the trends are pretty similar.


## With pilot data, draw the plot and determine sample size using the self-defined model
If you want to use the model defined by yourself. Then you need to write a "predict_model" function including your model. The function should take *train_data_x* and *train_data_y* as the first two inputs to train the model and then take *test_data_x* as the third input and return the predicted result of *test_data_x*. Then you could set `model` to *self* and set `func` to *predict_model*, and run the model using your self-defined function.
```{r}
library(e1071)

predict_model <- function(train_data_x, train_data_y, test_data_x){
    train_data = data.frame(train_data_x, as.factor(train_data_y))
    names(train_data)[length(train_data)] = "class"
    fit_svm<-svm(class~.,data=train_data,probability=TRUE)
    pred <- predict(fit_svm, test_data_x)
    return(pred)
}
```
```{r eval=FALSE}
result_pilot_self = ssd(x_pilot, y_pilot, model="self", func=predict_model)
```
```{r echo=FALSE, out.width = '100%'}
knitr::include_graphics("https://raw.githubusercontent.com/ShudongSun/SampleSizeDetermination/main/vignettes/2-1.jpeg")
```

You could use the following code to check the function you defined. The result has to be the predicted value of *test_data_x*.
```{r}
num_class=10
n_train=60
n_test=200

for(i in 1:num_class){
  class_i_ids = which(data$phenoid == names(table(data$phenoid))[i])
  
  train_test_i_ids = sample(class_i_ids, (n_train+n_test))
  train_i_data = data[train_test_i_ids[1:n_train],]
  test_i_data = data[train_test_i_ids[(n_train+1):(n_train+n_test)],]

  if(i == 1){
    train_data = train_i_data
    test_data = test_i_data
  }else{
    train_data = rbind(train_data, train_i_data)
    test_data = rbind(test_data, test_i_data)
  }
}

train_data_x = train_data[,-length(test_data)]
train_data_y = train_data$phenoid
test_data_x = test_data[,-length(test_data)]

result = predict_model(train_data_x, train_data_y, test_data_x)

```


## With pilot data and large true data, draw the plot and compare the result
If we have large enough true data and try to compare the plot drawn based on pilot data and the plot drawn based on true data, we could change `mode` to *true* and compare the results.
```{r eval=FALSE}
# prepare large true data
x_true = data[,-length(data)]
y_true = data[,length(data)]

# run the model using the previous pilot data
result_pilot_11 = ssd(x_pilot, y_pilot,model = "randomforest",index = "classification error",n_train_list=seq(from=30, to=600,by=30))
# run the model using the true data
result_true_11 = ssd(x_true , y_true ,model = "randomforest",index = "classification error",n_train_list=seq(from=30, to=600,by=30), mode="true")
```

