% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model_fitting.R
\name{ssd}
\alias{ssd}
\title{Sample Size Determination}
\usage{
ssd(
  x,
  y,
  model = "randomforest",
  func = NULL,
  index = "ARI",
  n_train_list = seq(from = 30, to = 600, by = 30),
  n_test = 300,
  mode = "pilot",
  num_repeat = 30,
  print_progress_bar = TRUE,
  n.cores = NULL
)
}
\arguments{
\item{x}{a data frame or a matrix of predictors to be fitted.}

\item{y}{A response vector.}

\item{model}{base classification model.
\itemize{
\item svm: Support Vector Machines. \code{\link[e1071]{svm}} in \code{e1071} package
\item randomforest: Random Forest. \code{\link[randomForest]{randomForest}} in \code{randomForest} package
\item tree: Classificatin Tree. \code{\link[tree]{tree}} in \code{tree} package
\item self: You can use your self-defined function. You need to pass your self-defined function via the "func" parameter.
}}

\item{func}{If you set "model" to "self", you have to pass your self-defined model function. This function should be able to take \emph{train_data_x} and \emph{train_data_y} as the first two inputs to train the model and then take \emph{test_data_x} as the third input and return the predicted scores of \emph{test_data_x} data. For example,

\preformatted{library(e1071)

predict_model <- function(train_data_x, train_data_y, test_data_x){
    train_data = data.frame(train_data_x, as.factor(train_data_y))
    names(train_data)[length(train_data)] = "class"
    fit_svm<-svm(class~.,data=train_data,probability=TRUE)
    pred <- predict(fit_svm, test_data_x)
    return(pred)
}

elbow = ssd(x_pilot, y_pilot, model="self", func=predict_model)
}}

\item{index}{the index used to judge the quality of the model.
\itemize{
\item classification error: what we usually mean.
\item ARI: Adjusted Rand Index.
\item AMI: Adjusted Mutual Information.
}}

\item{n_train_list}{a series of numbers which represent the generated training data size for each class.}

\item{n_test}{the generated test data size for each class.}

\item{mode}{The default value is "pilot", which means that we will see the input data(x and y) as the pilot data(usually small number), and use them to generate simulated data (corresponding to 'n_train_list'), and then get the curve and elbow point; "true" means that we will sample the data corresponding to 'n_train_list' from input data (x and y), and then get the curve and elbow point.}

\item{num_repeat}{The number of times to repeat for each training data size in order to get a average value of index to reduce the effect of randomness. The default value is 30.}

\item{print_progress_bar}{Whether to print the progress bar and elapsed time. The default value is TRUE.}

\item{n.cores}{The number of nodes to be forked when using multi-core parallel computing. If not being set(n.cores=NULL), \code{n.cores <- parallel::detectCores() - 1} would be used.}
}
\value{
Return the average classification errors/ARI/AMI of the repeat results for the selected mode.
}
\description{
build the model and determine the sample size based on elbow method of ARI and AMI.
}
\examples{
data_pmbc <- read.csv(system.file("extdata", "data_pmbc_24pc.csv", package = "SSD"),row.names=1)
data = data_pmbc

### use pilot data:
p = 15
table(data$phenoid)
num_class = length(table(data$phenoid))
num_PC = length(colnames(data))-1
for(i in 1:num_class){
  class_i_ids = which(data$phenoid == names(table(data$phenoid))[i])
  pilot_i_ids = sample(class_i_ids, p)
  pilot_i_data = data[pilot_i_ids,]
  if(i == 1){
    pilot_data = pilot_i_data
  }else{
    pilot_data = rbind(pilot_data, pilot_i_data)
  }
}
x_pilot = pilot_data[,-length(pilot_data)]
y_pilot = pilot_data[,length(pilot_data)]
table(pilot_data$phenoid)

result_pilot = ssd(x_pilot, y_pilot)

### use true data:

x_true = data[,-length(data)]
y_true = data[,length(data)]

result_true = ssd(x_true, y_true, mode="true")

}
